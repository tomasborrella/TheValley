{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiu5wKLXFHTBlJXFBxj5kv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomasborrella/TheValley/blob/main/notebooks/mds%2B4/spark01/Ejemplo_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeQLYo17pIcm"
      },
      "source": [
        "# Ejemplo de PySpark\n",
        "\n",
        "Notebook por [Tomás Borrella Martín](https://www.linkedin.com/in/tomasborrella/).\n",
        "\n",
        "### Enlaces de interés\n",
        "*   [Slides de presentación](https://docs.google.com/presentation/d/1xB2Hbfcx7eoqFu5BMTZV_uYJP7QgJnjavb7DhUnawTs/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8YNep9JB4ca"
      },
      "source": [
        "# 1. Datos\n",
        "Descargamos un archivo que contiene una canción en cada fila (simplificado para el ejemplo).\n",
        "\n",
        "NOTA: En un notebook, \"!\" ejecuta comandos del sistema desde dentro del notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSYUhmxz_RxQ"
      },
      "source": [
        "!wget -P /content/data 'https://raw.githubusercontent.com/tomasborrella/TheValley/main/data/spark01/simple_songs_log.txt' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnun5POxh_hX"
      },
      "source": [
        "# 2. Instalación Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuJjskSn9KeV"
      },
      "source": [
        "# Install JAVA\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oTR3cFa9ORq"
      },
      "source": [
        "# Install Spark\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZPnAX8i9XDc"
      },
      "source": [
        "# Install findspark\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI4QagUl9fy7"
      },
      "source": [
        "# Environment variables\n",
        "import os \n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sov8DPmr9nhE"
      },
      "source": [
        "# Find spark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g4Frp0P9q5c"
      },
      "source": [
        "# PySpark \n",
        "!pip install pyspark==3.1.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpQZYF3RieR1"
      },
      "source": [
        "# 3. Spark Context\n",
        "Punto de entrada para utilizar Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haPHnvwf9-Mz"
      },
      "source": [
        "# Imports\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuhcSzKETDLL"
      },
      "source": [
        "# Create Spark Context\n",
        "conf = SparkConf().setAppName(\"Primer ejemplo con Spark\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRxzlGwr-JGl"
      },
      "source": [
        "# Show config\n",
        "sc.getConf().getAll()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLoN1UP2q3Dk"
      },
      "source": [
        "## Primer RDD de Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhi4QchByeMG"
      },
      "source": [
        "first_rdd = sc.parallelize([1,2,3,4,5,6,7,8,9,10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLH0Cax2xCn0"
      },
      "source": [
        "type(first_rdd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1HVYPDEq_J4"
      },
      "source": [
        "first_rdd.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEpw-kmUyoGT"
      },
      "source": [
        "first_rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSSU90pMys8N"
      },
      "source": [
        "first_rdd.glom().collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1akpXVgirGqu"
      },
      "source": [
        "## RDD con los datos del log de canciones\n",
        "(versión simplificada)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm91xtNSwNBj"
      },
      "source": [
        "my_rdd = sc.textFile('/content/data/simple_songs_log.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCfm1S46xE-T"
      },
      "source": [
        "my_rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2wHqc1ZxX_y"
      },
      "source": [
        "type(my_rdd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNhLflOR3e-l"
      },
      "source": [
        "pairs = my_rdd.map(lambda x: (x, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vrvXumdrphY"
      },
      "source": [
        "type(pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EyC4jRc3qzd"
      },
      "source": [
        "pairs.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YziLh-564TpL"
      },
      "source": [
        "result = pairs.reduceByKey(lambda x, y: x + y)\n",
        "print(result.collect())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBRqac9L5JUD"
      },
      "source": [
        "result.glom().collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfczcwskfwW8"
      },
      "source": [
        "# Ejercicio propuesto\n",
        "\n",
        "Crear un RDD con el log completo (no la versión simplificada) y contar las canciones usando los métodos \"map\" y \"reduceByKey\" del RDD\n",
        "\n",
        "Pasos:\n",
        "1. Descargar el archivo completo de la siguiente ruta:\n",
        "https://raw.githubusercontent.com/tomasborrella/TheValley/main/data/spark01/complete_songs_log.txt\n",
        "2. Crear un RDD de Spark con el contenido del archivo.\n",
        "(Nota: importante tener un contexto de Spark disponible).\n",
        "3. Usar los métodos del RDD para contar las reproducciones de las canciones.\n",
        "\n",
        "Pista: Solo es necesario añadir un pequeño preprocesado en la fase de Map antes de devolver la tupla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XSc9RBqsQgb"
      },
      "source": [
        "# Spark Stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxHm2F98TkLx"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
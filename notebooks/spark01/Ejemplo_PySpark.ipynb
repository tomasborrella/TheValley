{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejemplo_PySpark.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPGf5822ufx2Exm3jQtKTyz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomasborrella/TheValley/blob/main/notebooks/spark01/Ejemplo_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeQLYo17pIcm"
      },
      "source": [
        "# Ejemplo de PySpark\n",
        "\n",
        "Notebook por [Tomás Borrella Martín](https://www.linkedin.com/in/tomasborrella/).\n",
        "\n",
        "### Enlaces de interés\n",
        "*   [Slides de presentación](https://docs.google.com/presentation/d/10HZGQnFNzRO63I9XRt-uQa6K9K2yAM71Wu-SYB0TL7c/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8YNep9JB4ca"
      },
      "source": [
        "# 1. Datos\n",
        "Descargamos un archivo que contiene una canción en cada fila (simplificado para el ejemplo).\n",
        "\n",
        "NOTA: En un notebook, \"!\" ejecuta comandos del sistema desde dentro del notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSYUhmxz_RxQ",
        "outputId": "15f1c28b-0ff7-4307-facf-21dc08b816f5"
      },
      "source": [
        "!wget -P /content/data 'https://raw.githubusercontent.com/tomasborrella/TheValley/main/data/spark01/simple_songs_log.txt' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 10:09:26--  https://raw.githubusercontent.com/tomasborrella/TheValley/main/data/spark01/simple_songs_log.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32939 (32K) [text/plain]\n",
            "Saving to: ‘/content/data/simple_songs_log.txt’\n",
            "\n",
            "simple_songs_log.tx 100%[===================>]  32.17K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-06-05 10:09:27 (4.75 MB/s) - ‘/content/data/simple_songs_log.txt’ saved [32939/32939]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnun5POxh_hX"
      },
      "source": [
        "# 2. Instalación Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuJjskSn9KeV"
      },
      "source": [
        "# Install JAVA\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oTR3cFa9ORq"
      },
      "source": [
        "# Install Spark\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZPnAX8i9XDc"
      },
      "source": [
        "# Install findspark\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI4QagUl9fy7"
      },
      "source": [
        "# Environment variables\n",
        "import os \n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sov8DPmr9nhE"
      },
      "source": [
        "# Find spark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g4Frp0P9q5c",
        "outputId": "085764b7-1452-475e-e8ee-113d1ce63509"
      },
      "source": [
        "# PySpark \n",
        "!pip install pyspark==3.1.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 71kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 19.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=4c08c6f1bd76febba30e772bcf000d16e9b429707ffc5cacbbf1b49b12c33768\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpQZYF3RieR1"
      },
      "source": [
        "# 3. Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haPHnvwf9-Mz"
      },
      "source": [
        "# Imports\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuhcSzKETDLL"
      },
      "source": [
        "# Create Spark Session\n",
        "spark = (SparkSession\n",
        "         .builder\n",
        "         .master(\"local[*]\")\n",
        "         .appName(\"Primer ejemplo con Spark\")\n",
        "         .getOrCreate()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRxzlGwr-JGl",
        "outputId": "9821a249-65c3-45bf-ed5c-b80085e2e68e"
      },
      "source": [
        "# Show config\n",
        "spark.sparkContext.getConf().getAll()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark.driver.port', '33979'),\n",
              " ('spark.app.startTime', '1622887977083'),\n",
              " ('spark.app.id', 'local-1622887978550'),\n",
              " ('spark.rdd.compress', 'True'),\n",
              " ('spark.app.name', 'Primer ejemplo con Spark'),\n",
              " ('spark.serializer.objectStreamReset', '100'),\n",
              " ('spark.master', 'local[*]'),\n",
              " ('spark.submit.pyFiles', ''),\n",
              " ('spark.executor.id', 'driver'),\n",
              " ('spark.submit.deployMode', 'client'),\n",
              " ('spark.sql.warehouse.dir', 'file:/content/spark-warehouse'),\n",
              " ('spark.ui.showConsoleProgress', 'true'),\n",
              " ('spark.driver.host', 'c2657a14be39')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLoN1UP2q3Dk"
      },
      "source": [
        "## Primer RDD de Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhi4QchByeMG"
      },
      "source": [
        "first_rdd = spark.sparkContext.parallelize([1,2,3,4,5,6,7,8,9,10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLH0Cax2xCn0",
        "outputId": "4c6c9b95-aadf-4d04-e965-16e58614f642"
      },
      "source": [
        "type(first_rdd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1HVYPDEq_J4",
        "outputId": "436bfe3d-aaa0-4365-862c-cb5dc83d6e85"
      },
      "source": [
        "first_rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEpw-kmUyoGT",
        "outputId": "646e4db5-fdea-4afe-b91b-507e9590a420"
      },
      "source": [
        "first_rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSSU90pMys8N",
        "outputId": "7aae8f09-3576-49ec-985f-cee34d2ed521"
      },
      "source": [
        "first_rdd.glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1akpXVgirGqu"
      },
      "source": [
        "## RDD con los datos del log de canciones\n",
        "(versión simplificada)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm91xtNSwNBj"
      },
      "source": [
        "my_rdd = spark.sparkContext.textFile('/content/data/simple_songs_log.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCfm1S46xE-T",
        "outputId": "a4a583d8-9324-4c73-adbd-b7844035ee8f"
      },
      "source": [
        "my_rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2wHqc1ZxX_y",
        "outputId": "dc5de087-af89-4094-c32c-36240574e3b9"
      },
      "source": [
        "type(my_rdd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNhLflOR3e-l"
      },
      "source": [
        "pairs = my_rdd.map(lambda x: (x, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vrvXumdrphY",
        "outputId": "cf3264bc-5157-4574-e6c1-619316fe0e78"
      },
      "source": [
        "type(pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EyC4jRc3qzd"
      },
      "source": [
        "pairs.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YziLh-564TpL",
        "outputId": "2b65dae2-aa4d-4207-9b83-c654013f7b75"
      },
      "source": [
        "result = pairs.reduceByKey(lambda x, y: x + y)\n",
        "print(result.collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Blinding Lights', 1131), ('The Box', 510), ('Dance Monkey', 828)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBRqac9L5JUD",
        "outputId": "0c4b763e-18fb-4f60-ef4a-712ff22ea7f7"
      },
      "source": [
        "result.glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Blinding Lights', 1131), ('The Box', 510)], [('Dance Monkey', 828)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfczcwskfwW8"
      },
      "source": [
        "# Ejercicio propuesto\n",
        "\n",
        "Crear un RDD con el log completo (no la versión simplificada) y contar las canciones usando los métodos \"map\" y \"reduceByKey\" del RDD\n",
        "\n",
        "Pasos:\n",
        "1. Descargar el archivo completo de la siguiente ruta:\n",
        "https://raw.githubusercontent.com/tomasborrella/TheValley/main/data/spark01/complete_songs_log.txt\n",
        "2. Crear un RDD de Spark con el contenido del archivo. (importante tener una sesión de Spark activa)\n",
        "3. Usar los métodos del RDD para contar las reproducciones de las canciones.\n",
        "\n",
        "Pista: Solo es necesario añadir un pequeño preprocesado en la fase de Map antes de devolver la tupla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XSc9RBqsQgb"
      },
      "source": [
        "# Spark Stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxHm2F98TkLx"
      },
      "source": [
        "spark.stop()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}